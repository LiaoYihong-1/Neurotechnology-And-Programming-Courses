{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_TextAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs6Yt1h1pO-0"
      },
      "source": [
        "В данной лабораторной работе будут показаны основы анализа текстовой информации. В ходе её выполнения мы познакомимся с этапами предварительной подготовки данных, а также применим машинное обучение для задачи классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiY7HEwBA5ht"
      },
      "source": [
        "Будем использовать датасет с текстами песен разных жанров: https://www.kaggle.com/mehedihasan9021/movie-script-dataset\n",
        "\n",
        "\n",
        "> Задание выполняется в google colab. Чтобы редактировать ноутбук, не забудьте сохранить его копию на диске. Скачайте файл по ссылке, загрузите в сессионное хранилище и запускайте ячейки с кодом, следуя инструкциям."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqSLYPq4XoXH"
      },
      "source": [
        "Читаем набор данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9OwJhjSnzjp"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NwVymy9wMHSF",
        "outputId": "0b7b3189-17c6-4464-c8f8-6fc63a33217b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>SongInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>CASTING CROWNS - WHO AM I LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>GLORY REVEALED - BY HIS WOUNDS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>CAEDMON'S CALL - GOD OF WONDERS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>MERCYME - I CAN ONLY IMAGINE LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>AARON SHUST - MY SAVIOR MY GOD LYRICS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       genre  ...                                SongInfo\n",
              "0  Christian  ...        CASTING CROWNS - WHO AM I LYRICS\n",
              "1  Christian  ...   GLORY REVEALED - BY HIS WOUNDS LYRICS\n",
              "2  Christian  ...  CAEDMON'S CALL - GOD OF WONDERS LYRICS\n",
              "3  Christian  ...     MERCYME - I CAN ONLY IMAGINE LYRICS\n",
              "4  Christian  ...   AARON SHUST - MY SAVIOR MY GOD LYRICS\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpByjtHQMASx",
        "outputId": "9d7a8418-680f-442a-d5a3-f5cb1e9eb7b9"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 558 entries, 0 to 557\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   genre     558 non-null    object\n",
            " 1   lyrics    558 non-null    object\n",
            " 2   SongInfo  558 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 13.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxP-iGu-MCi4"
      },
      "source": [
        "columns = data[['genre', 'lyrics']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bYF8acQSM6zE",
        "outputId": "7994f824-5512-49c6-d260-212735830e32"
      },
      "source": [
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Ha I dont care ha, about your past I just wan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Hoverin by my suitcase  Tryin to find a warm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>I dont know why I love you like I do  After a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>C. C. Rider Elvis Presley  Well now see., C. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Cynthia get up and dance to the music!  Get o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>558 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         genre                                             lyrics\n",
              "0    Christian   Who am I, that the Lord of all the earth Woul...\n",
              "1    Christian   Glory Revealed  By His Wounds He was pierced ...\n",
              "2    Christian   Lord of heaven and earth Lord of all creation...\n",
              "3    Christian   I can only imagine what it will be like When ...\n",
              "4    Christian   I am not skilled to understand What God has w...\n",
              "..         ...                                                ...\n",
              "553        R&B   Ha I dont care ha, about your past I just wan...\n",
              "554        R&B   Hoverin by my suitcase  Tryin to find a warm ...\n",
              "555        R&B   I dont know why I love you like I do  After a...\n",
              "556        R&B   C. C. Rider Elvis Presley  Well now see., C. ...\n",
              "557        R&B   Cynthia get up and dance to the music!  Get o...\n",
              "\n",
              "[558 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM6VU_qPXvId"
      },
      "source": [
        "Посмотрим какие жанры присутствуют в датасете. Для этого выведем уникальные значения столбца:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgU-qG2iM74F",
        "outputId": "7e560987-3640-4ceb-a420-f8862765d5df"
      },
      "source": [
        "columns['genre'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Christian', 'Country', 'Hip-Hop', 'Pop', 'Rock', 'R&B'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De2qmchpX2-a"
      },
      "source": [
        "Посчитаем также сколько песен каждого жанра представлено:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQotoiKyOMwl",
        "outputId": "bb767949-0411-4361-a720-0db3b53ff18f"
      },
      "source": [
        "columns['genre'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pop          100\n",
              "Rock          95\n",
              "Christian     94\n",
              "Hip-Hop       91\n",
              "R&B           91\n",
              "Country       87\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSGSPwtzxlyA"
      },
      "source": [
        "Оставляем только 2 жанра, которые планируем отличать друг от друга. Для примера будут использованы Christian и Hip-Hop, позднее в формулировке задания нужно будет сгенерировать собственную пару жанров. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC3pzAFS1ofC"
      },
      "source": [
        "columns = columns[(columns.genre == 'Christian') | (columns.genre == 'Hip-Hop')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aT2_kEVY2dw"
      },
      "source": [
        "###Предварительная обработка текстовых данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4il3oZFY_Kw"
      },
      "source": [
        "Для того, чтобы применять текстовые данные для обучения той или иной модели машинного обучения, их нужно привести в подходящий для этого вид. В этом нам помогут следующие шаги предварительной подготовки:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfTWe_1oCrsd"
      },
      "source": [
        "####Приведение к нижнему регистру"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2GZxS6PZkcx"
      },
      "source": [
        "Так как слова (например) \"Beer\" и \"beer\" будут считаться разными словами из-за разницы в регистре буквы b, а первая буква предложения, как правило, является заглавной, важно привести все слова предложения к нижнему регистру. Таким образом, \"beer\", встретившееся в начале предложения и в его середине, будут распознаны как одно слово."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq9MqtqoW2ce"
      },
      "source": [
        "lowered = columns['lyrics'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYUruNhrCFjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35dc73b9-b239-4b5a-d5ab-4596d14f83ff"
      },
      "source": [
        "columns['lowered'] = lowered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4YULmIC9oZ"
      },
      "source": [
        "####Токенизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZZIXNXebXvi"
      },
      "source": [
        "Имеющиеся тексты нужно разбить на отдельные слова. Такой процесс называется ***токенизация***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ws0-pYLCpI5",
        "outputId": "d2ea19cb-f4fd-43dc-a251-208d77b5dc87"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxi9nYbMDGWa"
      },
      "source": [
        "tokened = columns.apply(lambda row: nltk.word_tokenize(row['lowered']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqSXoypQDNE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7e7da9-1d3f-4c2e-aab2-a04761367b1d"
      },
      "source": [
        "columns['tokened'] = tokened"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOISss1fGOtf"
      },
      "source": [
        "####Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo0gIbfamIqr"
      },
      "source": [
        "***Стоп-словами*** называются распространённые слова, не несущие особой смысловой нагрузки, а значит никак не помогающие в последующей задаче классификации. Такие слова мы считаем шумом, и, соответственно, удаляем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKUN9izHnQfR"
      },
      "source": [
        "Существует специальный корпус стоп-слов на разных языках. Так как сейчас мы имеем дело с текстами на английском языке, выведем стоп-слова для английского:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKkAzYAeDbhN",
        "outputId": "d52210ec-2563-43ca-af58-de9193d5ac4b"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43f5-hujGW7l"
      },
      "source": [
        "noise = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YFPt0YxGf9J"
      },
      "source": [
        "withoutstop = columns['tokened'].apply(lambda x: [item for item in x if item not in noise])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvUp4qWzGlMr"
      },
      "source": [
        "without_stop = []\n",
        "for a in withoutstop:    \n",
        "    without_stop.append(\", \".join(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLJ1ezBGnoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e44bc9-8cd1-4677-b5f9-5c8e03b2744c"
      },
      "source": [
        "columns['without_stop'] = without_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWIlOfFOPId-"
      },
      "source": [
        "####Лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiNsgTkFPOjX"
      },
      "source": [
        "У одного и того же слова бывают разные формы. Например, dances - форма слова dance. Лемматизация - это приведение к ***лемме*** - исходной форме слова. Её также необходимо применить к нашим данным, чтобы разные формы слова не считались за отдельные слова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KA2A_wgUUfW"
      },
      "source": [
        "Существует целый ряд лемматизаторов, которые показывают себя с разной эффективностью на разных языках. Для работы с английским языком эффективен **WordNetLemmatizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR5Lr4WzGt5Q",
        "outputId": "3dcf384a-f753-4ccf-a74c-8369337d1c13"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i7WLP9-Z0_L",
        "outputId": "c26a1617-bb3a-4d23-d364-7d407781977e"
      },
      "source": [
        "print(lemmatizer.lemmatize(\"dances\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcmk4VWvb7Mq"
      },
      "source": [
        "lemmatized = columns['without_stop'].apply(lambda x: [lemmatizer.lemmatize(x)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puuud0HJdJRy"
      },
      "source": [
        "lemma = []\n",
        "for a in lemmatized:    \n",
        "    lemma.append(\", \".join(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTLDzaHFdMMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d038aca-46cb-49fa-f22d-cd970b5e91d1"
      },
      "source": [
        "columns['lemmatized'] = lemma"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkfqMYftynRV"
      },
      "source": [
        "Таким образом, на каждом этапе мы добавляли столбец с той или иной модификацией, чтобы получить пригодные для обучения данные. Посмотрим на датафрейм, который получился:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "ixDtw5yEyklr",
        "outputId": "3f202a57-4bdc-4240-c788-b9495b6c6d3d"
      },
      "source": [
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>lowered</th>\n",
              "      <th>tokened</th>\n",
              "      <th>without_stop</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>who am i, that the lord of all the earth woul...</td>\n",
              "      <td>[who, am, i, ,, that, the, lord, of, all, the,...</td>\n",
              "      <td>,, lord, earth, would, care, know, name, would...</td>\n",
              "      <td>,, lord, earth, would, care, know, name, would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>glory revealed  by his wounds he was pierced ...</td>\n",
              "      <td>[glory, revealed, by, his, wounds, he, was, pi...</td>\n",
              "      <td>glory, revealed, wounds, pierced, transgressio...</td>\n",
              "      <td>glory, revealed, wounds, pierced, transgressio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>lord of heaven and earth lord of all creation...</td>\n",
              "      <td>[lord, of, heaven, and, earth, lord, of, all, ...</td>\n",
              "      <td>lord, heaven, earth, lord, creation, lord, hea...</td>\n",
              "      <td>lord, heaven, earth, lord, creation, lord, hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>i can only imagine what it will be like when ...</td>\n",
              "      <td>[i, can, only, imagine, what, it, will, be, li...</td>\n",
              "      <td>imagine, like, walk, side, imagine, eyes, see,...</td>\n",
              "      <td>imagine, like, walk, side, imagine, eyes, see,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>i am not skilled to understand what god has w...</td>\n",
              "      <td>[i, am, not, skilled, to, understand, what, go...</td>\n",
              "      <td>skilled, understand, god, willed, ,, god, plan...</td>\n",
              "      <td>skilled, understand, god, willed, ,, god, plan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Dirty dog Im, Im a dirty dog Im a dirty dog I...</td>\n",
              "      <td>dirty dog im, im a dirty dog im a dirty dog i...</td>\n",
              "      <td>[dirty, dog, im, ,, im, a, dirty, dog, im, a, ...</td>\n",
              "      <td>dirty, dog, im, ,, im, dirty, dog, im, dirty, ...</td>\n",
              "      <td>dirty, dog, im, ,, im, dirty, dog, im, dirty, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Regulators, we regulate any stealing of his p...</td>\n",
              "      <td>regulators, we regulate any stealing of his p...</td>\n",
              "      <td>[regulators, ,, we, regulate, any, stealing, o...</td>\n",
              "      <td>regulators, ,, regulate, stealing, property, d...</td>\n",
              "      <td>regulators, ,, regulate, stealing, property, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Have you ever met a girl that you tried to da...</td>\n",
              "      <td>have you ever met a girl that you tried to da...</td>\n",
              "      <td>[have, you, ever, met, a, girl, that, you, tri...</td>\n",
              "      <td>ever, met, girl, tried, date, year, make, love...</td>\n",
              "      <td>ever, met, girl, tried, date, year, make, love...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Yo, yo, yo They wanna know  Whos that girl? (...</td>\n",
              "      <td>yo, yo, yo they wanna know  whos that girl? (...</td>\n",
              "      <td>[yo, ,, yo, ,, yo, they, wan, na, know, whos, ...</td>\n",
              "      <td>yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...</td>\n",
              "      <td>yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>3 6 9, damn shes fine Hopin she can sock it t...</td>\n",
              "      <td>3 6 9, damn shes fine hopin she can sock it t...</td>\n",
              "      <td>[3, 6, 9, ,, damn, shes, fine, hopin, she, can...</td>\n",
              "      <td>3, 6, 9, ,, damn, shes, fine, hopin, sock, one...</td>\n",
              "      <td>3, 6, 9, ,, damn, shes, fine, hopin, sock, one...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>185 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         genre  ...                                         lemmatized\n",
              "0    Christian  ...  ,, lord, earth, would, care, know, name, would...\n",
              "1    Christian  ...  glory, revealed, wounds, pierced, transgressio...\n",
              "2    Christian  ...  lord, heaven, earth, lord, creation, lord, hea...\n",
              "3    Christian  ...  imagine, like, walk, side, imagine, eyes, see,...\n",
              "4    Christian  ...  skilled, understand, god, willed, ,, god, plan...\n",
              "..         ...  ...                                                ...\n",
              "267    Hip-Hop  ...  dirty, dog, im, ,, im, dirty, dog, im, dirty, ...\n",
              "268    Hip-Hop  ...  regulators, ,, regulate, stealing, property, d...\n",
              "269    Hip-Hop  ...  ever, met, girl, tried, date, year, make, love...\n",
              "270    Hip-Hop  ...  yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...\n",
              "271    Hip-Hop  ...  3, 6, 9, ,, damn, shes, fine, hopin, sock, one...\n",
              "\n",
              "[185 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fTc3speuRU_"
      },
      "source": [
        "####Разделим данные на обучающую и тестовую выборки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slicW92xunS6"
      },
      "source": [
        "x_train - тексты, на которых мы обучаем модель. В данном случае мы используем столбец lemmatized, так как он содержит данные, прошедшие все этапы подготовки \n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "y_train - жанры, соответствующие текстам, на которых модель обучается - столбец genre\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "x_test - точно такие же тексты из набора данных, на которых мы будем проверять, насколько модель научилась предсказывать жанр\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "y_test - жанры, соответствующие x_test. т.е. мы смотрим, насколько предсказания соответствуют содержимому этой переменной, чтобы оценить качество обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNflRzghthgt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_test, y_train, y_test = train_test_split(columns.lemmatized, columns.genre, train_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUGVD0A2uWHs",
        "outputId": "1bb088ec-f3d0-4da0-cb44-f1c5b9ae1396"
      },
      "source": [
        "columns.genre.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Christian    94\n",
              "Hip-Hop      91\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvUGd5D45Lvg"
      },
      "source": [
        "####Векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOZdvHTa8y3U"
      },
      "source": [
        "Следующий этап - ***векторизация***, то есть представление текста в численном виде, чтобы закодированные данные в дальнейшем использовать на модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APRGsKZx5JVu"
      },
      "source": [
        "Иногда помимо отдельных слов для улучшения качества обучения будет полезно использовать также комбинации из 2-3 слов. Здесь мы используем векторизатор CountVectorizer, который имеет встроенный метод - мешок n-грамм.\n",
        "\n",
        "> n = 1 - униграмма (для обучения используются слова по отдельности)\n",
        "\n",
        "> n = 2 - биграмма (для обучения используются пары слов)\n",
        "\n",
        "> n = 3 - триграмма (для обучения используются тройки слов)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Qsuu8F24RX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9eEKTEP-R_6"
      },
      "source": [
        "Задаём для векторизатора ngram_range=(1, 3), то есть используем все варианты n от 1 до 3 и прибегаем как к униграммам, так и к биграммам и триграммам:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-7CcA8d24Dd"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "vectorized_x_train = vectorizer.fit_transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9m6sTC0-lmB"
      },
      "source": [
        "### Классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9TxA5ek-vvi"
      },
      "source": [
        "Для задачи классификации используем Наивный Байесовский Классификатор - простой вероятностный классификатор, основанный на применении теоремы Байеса со строгими предположениями о независимости. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Qo0JJPvzO7"
      },
      "source": [
        "#импортируем байесовский классификатор\n",
        "from sklearn.naive_bayes import MultinomialNB "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOJS1mskyLnf",
        "outputId": "627cadd4-207f-4918-86c3-779113d86019"
      },
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUW3yo_FyLcr"
      },
      "source": [
        "# тестовую выборку просто векторизировали\n",
        "vectorized_x_test = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZ_Yn7j42JB"
      },
      "source": [
        "Посмотрим предсказания для тестовой выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwjjKPF64zTQ",
        "outputId": "c07a2ad5-3ab6-4ba2-fc9e-7ed718f75dc6"
      },
      "source": [
        "clf.predict(vectorized_x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Christian', 'Christian',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Christian', 'Hip-Hop',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Hip-Hop', 'Christian',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Hip-Hop', 'Hip-Hop',\n",
              "       'Hip-Hop', 'Christian', 'Christian', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Christian', 'Hip-Hop',\n",
              "       'Christian', 'Christian', 'Hip-Hop', 'Christian', 'Christian',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Hip-Hop', 'Hip-Hop',\n",
              "       'Christian', 'Hip-Hop', 'Hip-Hop', 'Christian', 'Hip-Hop',\n",
              "       'Hip-Hop'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2sNKSRk46ao"
      },
      "source": [
        "Получим оценки классификации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W1R9x6J3GVS",
        "outputId": "6d991554-cbcb-43a2-ded6-83e80e5935fd"
      },
      "source": [
        "from sklearn.metrics import * \n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Christian       0.93      0.96      0.95        28\n",
            "     Hip-Hop       0.96      0.93      0.95        28\n",
            "\n",
            "    accuracy                           0.95        56\n",
            "   macro avg       0.95      0.95      0.95        56\n",
            "weighted avg       0.95      0.95      0.95        56\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gxRZ_lI-4Da"
      },
      "source": [
        "###Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Atec9Uy_CYJ"
      },
      "source": [
        "1) Запустить ячейку ниже, чтобы получить 2 жанра. Для полученных жанров провести все этапы предварительной обработки текста (как в примере), обучить наивный байесовский классификатор, численно оценить его работу."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxkZ901zyLPQ"
      },
      "source": [
        " import random \n",
        " lst = ['Christian', 'Country', 'Pop', 'Rock', 'R&B'] \n",
        " print('ваши жанры', random.choice(lst), 'и', random.choice(lst)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNAI2TMBxMDH"
      },
      "source": [
        "Для улучшения качества обучения модели можно попробовать избавиться от знаков препинания и проследить, чтобы процентное соотношение песен обоих жанров было примерно 50 на 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWdnLBHf_onv"
      },
      "source": [
        "2) Найти (нагуглить) по песне каждого из жанров, которые Вам достались, после необходимой обработки их текстов определить жанр обеих песен с помощью обученной в ходе выполнения предыдущего пункта модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtmpuwX6AZy6"
      },
      "source": [
        "3) С помощью набора данных по ссылке аналогичным образом научить модель отличать тексты песен Дэвида Боуи от текстов песен Пола МакКартни \n",
        "https://www.kaggle.com/italomarcelo/dataset-lyrics-music-mini"
      ]
    }
  ]
}